# Shell Task Execution in JarvisAgent (make-example Workflow)

This document describes how JarvisAgent executes **shell-based tasks** for the `make-example` workflow (the small “makefile-style” compilation demo), which builds:

- `lib1.o`, `lib2.o`, `main.o`, `app.o`
- `libmylib.a` (static library)
- `myapp` (final executable)

It focuses on **what happens**, in **which order**, and **which major components are involved**, based on the current code and the log output you captured.

---

## 0. How we came up with `make_example.jcwf` (AI-assisted)

This workflow file was generated by **JarvisAgent itself** by sending an AI request to OpenAI, using the normal “queue folder” mechanism:

1. You dropped a small “environment” into `../queue/`:
   - `STNG_technical_tone.txt` (tone / style)
   - `CNTX_jcwf_spec.txt` (the JCWF spec / schema description)
   - `TASK_generate_jcwf_make_example.txt` (instruction: generate a JCWF for the make-example build)
2. You provided the build problem statement as an input file:
   - `PROB_make_process_context.txt` (the make-style build description + expected task ordering)

JarvisAgent detected these files, compiled the environment (STNG/CNTX/TASK), then treated the `PROB_...` file as a query and sent it to the configured OpenAI endpoint. In your log this shows up as:

```text
[Application] [info] New file detected: ../queue/STNG_technical_tone.txt
[Application] [info] New file detected: ../queue/CNTX_jcwf_spec.txt
[Application] [info] New file detected: ../queue/PROB_make_process_context.txt
[Application] [info] New file detected: ../queue/TASK_generate_jcwf_make_example.txt
...
[Application] [info] No output found for '../queue/PROB_make_process_context.txt', scheduling query
...
[Engine] [info] Response: { ... "model": "gpt-4.1-mini-2025-04-14", ... }
...
[Application] [info] message: { <JCWF JSON> }
[Application] [info] FileWriter: Wrote output file with header: ../queue/PROB_make_process_context.output.txt
```

The resulting `.output.txt` contained the JCWF JSON (plus a small JarvisAgent header). You then:

- copied the JSON body into `../workflows/make_example.jcwf`, and
- re-ran JarvisAgent to validate that the workflow actually builds the targets (after deleting `*.o`, `*.a`, and `myapp`).

---

## 1. High-level Data Flow

At a high level, a run of the `make-example` workflow goes through these stages:

1. **Engine + App startup**
2. **Workflows loaded and registered**
3. **Trigger registered and fired**
4. **Workflow orchestrated as a DAG of tasks**
5. **Shell tasks executed in dependency order**
6. **Workflow marked as complete**

In log form, the critical lines are (abridged):

```text
[Application] [info] WorkflowRegistry::LoadDirectory scanning ../workflows
[Application] [info] Loading workflow file ../workflows/make_example.jcwf
[Application] [info] Registered workflow make-example
[Application] [info] Validating workflow make-example
[Application] [info] TriggerEngine::AddAutoTrigger: registered auto trigger 'auto' for workflow 'make-example'
[Application] [info] TriggerEngine::FireTrigger: firing trigger 'auto' for workflow 'make-example'
[Application] [info] JarvisAgent: Trigger fired for workflow 'make-example' (trigger id 'auto')
[Application] [info] WorkflowOrchestrator: Starting workflow 'make-example' (run id 'make-example_...')
```

Then the shell tasks (when outputs are not up-to-date):

```text
[Application] [info] [shell] Executing shell task 'compile_lib1'
[Application] [info] [shell] Command: scripts/compile.sh .../lib1.cpp .../lib1.o -O3
...
[Application] [info] [shell] Executing shell task 'make_static_lib'
[Application] [info] [shell] Command: scripts/archive.sh .../lib1.o .../lib2.o .../libmylib.a
...
[Application] [info] [shell] Executing shell task 'make_executable'
[Application] [info] [shell] Command: scripts/link.sh .../main.o .../app.o .../libmylib.a .../myapp -O3
[Application] [info] WorkflowOrchestrator: Workflow 'make-example' (...) completed successfully
```

---

## 2. Components / Classes Involved

From the logs and the current architecture, these are the main components that participate in running shell tasks for JCWF workflows:

1. **Engine / Core**
   - Reads the **engine config** (format, folders, API settings, etc.).
   - Starts the main run loop, logging, thread pool, and file watcher.
   - Hands control to the **JarvisAgent application**.

2. **JarvisAgent Application**
   - Initializes subsystems (web server, Python engine, workflow system).
   - Calls **WorkflowRegistry::LoadDirectory** to load `.jcwf` files:
     - `../workflows/make_example.jcwf` in your case.
   - Calls **WorkflowRegistry::LoadFile** for each workflow file and registers it.

3. **WorkflowRegistry**
   - Parses the JCWF JSON (`make_example.jcwf`).
   - Registers:
     - Workflow metadata (id, label, etc.).
     - Tasks (nodes in the DAG): `compile_lib1`, `compile_lib2`, `make_static_lib`, `compile_main`, `compile_app`, `make_executable`.
     - Dataflow edges between tasks (the `dataflow` array in the JCWF).

4. **TriggerEngine**
   - After the workflow is registered and validated, a default **auto trigger** is registered:
     - `TriggerEngine::AddAutoTrigger: ... 'auto' for workflow 'make-example'`.
   - Immediately fires that trigger at startup:
     - `TriggerEngine::FireTrigger: firing trigger 'auto' for workflow 'make-example'`.
   - The fired trigger tells the orchestrator to start a run of `make-example`.

5. **WorkflowOrchestrator**
   - Receives: “start workflow `make-example` with run id `make-example_...`”.
   - Resolves the **task graph** (tasks + `depends_on` + `dataflow`):
     - Finds tasks with no unmet dependencies and schedules them.
     - Tracks which tasks have completed.
     - When all dependencies of a task are done, it schedules the next dependent task.
   - For **shell tasks**, it uses the **shell-execution helper** (the code that emits `[shell]` log lines) to:
     - Build the command line.
     - Launch the external process.
     - Wait for exit and record success/failure.
   - If a task is considered up-to-date, it can be skipped (see section 5).

6. **Shell Execution Helper (shell task runner)**
   - It is responsible for these log lines:
     - `[shell] Executing shell task 'compile_lib1'`
     - `[shell] Command: scripts/compile.sh .../lib1.cpp .../lib1.o -O3`
   - Performs the following steps:
     1. Resolves **file inputs** and **file outputs** from the JCWF:
        - For example, for `compile_lib1`:
          - `file_inputs`: `["lib1.cpp"]` → resolved as `../workflows/lib1.cpp`
          - `file_outputs`: `["lib1.o"]`   → resolved as `../workflows/lib1.o`
     2. Resolves any **dataflow inputs/outputs** (like `${input[0]}`, `${output[0]}` in `params.args`).
     3. Constructs the **final command line** from the JCWF `params`:
        - `command`: `scripts/compile.sh`
        - `args`: `["${input[0]}", "${output[0]}", "-O3"]` → becomes `.../lib1.cpp .../lib1.o -O3`.
     4. Spawns a **child process** to run the command.
     5. Collects the exit code and reports success/failure back to the orchestrator.

7. **External Scripts + Toolchain**
   - These are the actual shell scripts that do the work.
   - In your current setup, the scripts are written to accept optional extra flags passed from JCWF (e.g. `-O3`):

   ```bash
   # scripts/compile.sh
   g++ -Wall -Wextra -std=c++20 -c "$SOURCE" -o "$OUTPUT" "${@:3}"

   # scripts/archive.sh
   ar rcs "$ARCHIVE" "$OBJ1" "$OBJ2"

   # scripts/link.sh
   g++ -Wall -Wextra "$MAIN_OBJ" "$APP_OBJ" "$ARCHIVE" -o "$OUTPUT" "${@:5}"
   ```

   - JCWF + JarvisAgent decides **what to run, and in which order**.
   - The shell scripts + `g++`/`ar`/linker actually do the compilation and linking.

---

## 3. Task Order and Dependencies

From `make_example.jcwf`, the task graph is:

1. **Leaf tasks (no depends_on):**
   - `compile_lib1`
   - `compile_lib2`
   - `compile_main`
   - `compile_app`

2. **Intermediate task:**
   - `make_static_lib`
     - `depends_on`: `["compile_lib1", "compile_lib2"]`
     - `file_inputs`: `["lib1.o", "lib2.o"]`
     - Produces: `libmylib.a`

3. **Final task:**
   - `make_executable`
     - `depends_on`: `["compile_main", "compile_app", "make_static_lib"]`
     - `file_inputs`: `["main.o", "app.o", "libmylib.a"]`
     - Produces: `myapp`

So the orchestrator runs them in this DAG order:

```text
Step 1: compile_lib1, compile_lib2, compile_main, compile_app  (can run in parallel)
Step 2: make_static_lib                                       (requires lib1.o + lib2.o)
Step 3: make_executable                                       (requires main.o + app.o + libmylib.a)
```

---

## 4. Detailed Shell Task Example

Let’s look at `compile_lib1` as a concrete example, step by step.

### 4.1. JCWF fragment

```jsonc
"compile_lib1": {
  "id": "compile_lib1",
  "type": "shell",
  "label": "Compile lib1.cpp to lib1.o",
  "file_inputs": ["lib1.cpp"],
  "file_outputs": ["lib1.o"],
  "params": {
    "command": "scripts/compile.sh",
    "args": ["${input[0]}", "${output[0]}", "-O3"]
  },
  "outputs": {
    "object": { "type": "string" }
  }
}
```

### 4.2. How it is executed

1. **WorkflowOrchestrator** picks `compile_lib1` as ready to run (no dependencies).
2. It looks at `type: "shell"` and calls into the **shell task executor**.
3. The executor:
   - Resolves `file_inputs[0] = "lib1.cpp"` → `../workflows/lib1.cpp`.
   - Resolves `file_outputs[0] = "lib1.o"`  → `../workflows/lib1.o`.
   - Maps `${input[0]}` → the resolved input path.
   - Maps `${output[0]}` → the resolved output path.
4. It constructs the command:

   ```text
   scripts/compile.sh ../workflows/lib1.cpp ../workflows/lib1.o -O3
   ```

5. It logs:

   ```text
   [shell] Executing shell task 'compile_lib1'
   [shell] Command: scripts/compile.sh .../lib1.cpp .../lib1.o -O3
   ```

6. It spawns the child process, where `compile.sh` runs:

   ```bash
   #!/usr/bin/env bash
   set -euo pipefail

   SOURCE="$1"
   OUTPUT="$2"

   echo "[compile] $SOURCE -> $OUTPUT"

   g++ -Wall -Wextra -std=c++20 -c "$SOURCE" -o "$OUTPUT" "${@:3}"
   ```

7. On success (exit code 0), the orchestrator marks `compile_lib1` as **completed**, and this unblocks `make_static_lib` once `compile_lib2` is also done.

---

## 5. What Happens If We Run the Workflow Again?

With your recent change (“Add task freshness checks and skip up-to-date tasks”), the orchestrator can now skip tasks that are considered up-to-date.

In logs, a skipped task looks like this:

```text
[Application] [info] WorkflowOrchestrator: Task 'compile_lib1' is up to date → skipped
```

And a “rebuild everything” run (after deleting outputs) looks like this:

```text
[Application] [info] [shell] Executing shell task 'compile_lib1'
...
[Application] [info] [shell] Executing shell task 'make_executable'
```

Practical implication for `make-example`:

- If you remove `*.o`, `*.a`, and `myapp`, the run will rebuild everything.
- If you re-run without changing inputs, you’ll see “up to date → skipped” for tasks, and the workflow completes quickly.

---

## 6. Summary

- **How the JCWF was produced**:
  - JarvisAgent sent `PROB_make_process_context.txt` (with STNG/CNTX/TASK environment) to OpenAI.
  - The model returned a JCWF JSON.
  - You copied the JSON into `../workflows/make_example.jcwf` and validated it by executing the workflow.

- **Classes / components involved (high level)**:
  - Engine/Core (config + run loop)
  - JarvisAgent Application (initialization + subsystem wiring)
  - WorkflowRegistry (parse & register JCWF workflows)
  - TriggerEngine (auto + other triggers)
  - WorkflowOrchestrator (task DAG scheduling + skip up-to-date tasks)
  - Shell task executor helper (constructs commands & spawns child processes)
  - External shell scripts (`compile.sh`, `archive.sh`, `link.sh`) and toolchain (`g++`, `ar`, linker)

- **Order of operations for `make-example`**:
  1. Engine + JarvisAgent start.
  2. Workflows loaded from `../workflows`.
  3. `make-example` registered and validated.
  4. Auto trigger `auto` registered and fired.
  5. WorkflowOrchestrator runs tasks in DAG order:
     - `compile_lib1`, `compile_lib2`, `compile_main`, `compile_app`
     - `make_static_lib`
     - `make_executable`
  6. Shell executor runs each task’s `command + args` as an external process (unless the task is skipped as up-to-date).
  7. On success of all tasks, run is marked as complete.
## 7. Queue artifacts that generated the JCWF (STNG / CNTX / TASK / PROB)

When JarvisAgent generated `make_example.jcwf`, it did so from the standard queue inputs:

- **STNG_**: style / behavior rules for the model output
- **CNTX_**: background context (here: the JCWF specification)
- **TASK_**: the concrete instruction (“generate a Makefile-style build workflow”)
- **PROB_**: the problem statement and the produced output

Below are the captured file contents from `../queue/` (with `CNTX_jcwf_spec.txt` intentionally truncated as requested).

### 7.1 `STNG_technical_tone.txt`

```text
STNG_technical_tone.txt
Technical tone and behavior rules:

- Write in a precise, technical tone.
- Be concise, but do not omit critical details.
- Prefer structured output: short sections, bullet lists, and code blocks.
- If something is unknown or ambiguous, say so explicitly and ask for the missing info.
- Do not guess, embellish, or invent behavior/features.
- Use exact filenames, commands, and JSON fields when referencing them.
- For code: prefer C++20 examples, Allman braces, and do not omit braces for single-line if-statements.

Output format preference:
- When asked to generate a JCWF file, output valid JSON only (no surrounding markdown).
```

### 7.2 `CNTX_jcwf_spec.txt` (excerpt)

```text
CNTX_jcwf_spec.txt
This file contains the current JC Workflow File Format (JCWF) specification used by JarvisAgent.

# JC Workflow File Format™ (extension jcwf)

Copyright (c) 2025 JC Technolabs<br>
License: GPL-3.0

[..]
```

### 7.3 `TASK_generate_jcwf_make_example.txt`

```text
TASK_generate_jcwf_make_example.txt
Create a JC Workflow File (JCWF) JSON document that represents a Makefile-style build for the example files:

- Compile: lib1.cpp -> lib1.o
- Compile: lib2.cpp -> lib2.o
- Archive: lib1.o + lib2.o -> libmylib.a
- Compile: main.cpp -> main.o
- Compile: app.cpp -> app.o
- Link: main.o + app.o + libmylib.a -> myapp

Requirements:
- The workflow MUST follow the JCWF specification provided in CNTX.
- Use shell tasks and the scripts:
  - scripts/compile.sh
  - scripts/archive.sh
  - scripts/link.sh
- Use file_inputs / file_outputs for freshness checks.
- Use dataflow to wire task outputs into downstream task inputs, as in the working make_example.jcwf pattern:
  - compile_* tasks expose output slot "object"
  - archive task exposes output slot "archive"
- For the archive and link tasks, declare named required inputs (obj1/obj2 and main_obj/app_obj/archive) that are satisfied via dataflow.
- Include compiler optimization "-O3" for compilation and linking:
  - Either pass it via params.args (recommended) or document an equivalent mechanism that works with the scripts.
- Keep paths relative (e.g., lib1.cpp, lib1.o, myapp).
- Output: valid JSON only.

Do not include explanations, only the JCWF JSON.
```

### 7.4 `PROB_make_process_context.txt`

```text
PROB_make_process_context.txt
Define the make/build process for the example files based on the following documentation.

---
# Shell Task Execution in JarvisAgent (make-example Workflow)

This document describes how JarvisAgent executes **shell-based tasks** for the `make-example` workflow (the small “makefile-style” compilation demo), which builds:

- `lib1.o`, `lib2.o`, `main.o`, `app.o`
- `libmylib.a` (static library)
- `myapp` (final executable)

It focuses on **what happens**, in **which order**, and **which major components are involved**, based on the current code and the log output you captured.

## 1. High-level Data Flow

At a high level, a run of the `make-example` workflow goes through these stages:

1. **Engine + App startup**
2. **Workflows loaded and registered**
3. **Trigger registered and fired**
4. **Workflow orchestrated as a DAG of tasks**
5. **Shell tasks executed in dependency order**
6. **Workflow marked as complete**

In log form, the critical lines are (abridged):

```text
[Application] [info] WorkflowRegistry::LoadDirectory scanning ../workflows
[Application] [info] Loading workflow file ../workflows/make_example.jcwf
[Application] [info] Registered workflow make-example
[Application] [info] Validating workflow make-example
[Application] [info] TriggerEngine::AddAutoTrigger: registered auto trigger 'auto' for workflow 'make-example'
[Application] [info] TriggerEngine::FireTrigger: firing trigger 'auto' for workflow 'make-example'
[Application] [info] JarvisAgent: Trigger fired for workflow 'make-example' (trigger id 'auto')
[Application] [info] WorkflowOrchestrator: Starting workflow 'make-example' (run id 'make-example_...')
```

Then the shell tasks:

```text
[Application] [info] [shell] Executing shell task 'compile_lib1'
[Application] [info] [shell] Command: scripts/compile.sh ../workflows/lib1.cpp ../workflows/lib1.o
...
[Application] [info] [shell] Executing shell task 'make_static_lib'
[Application] [info] [shell] Command: scripts/archive.sh ../workflows/lib1.o ../workflows/lib2.o ../workflows/libmylib.a
...
[Application] [info] [shell] Executing shell task 'make_executable'
[Application] [info] [shell] Command: scripts/link.sh ../workflows/main.o ../workflows/app.o ../workflows/libmylib.a ../workflows/myapp
[Application] [info] WorkflowOrchestrator: Workflow 'make-example' (...) completed successfully
```

## 2. Components / Classes Involved

- Engine / Core
- JarvisAgent Application
- WorkflowRegistry
- TriggerEngine
- WorkflowOrchestrator
- Shell execution helper (shell task runner)
- External scripts + toolchain (g++, ar, linker)

## 3. Task Order and Dependencies

DAG order:

- Parallel leaf tasks:
  - compile_lib1, compile_lib2, compile_main, compile_app
- Then:
  - make_static_lib (depends_on: compile_lib1, compile_lib2)
- Then:
  - make_executable (depends_on: compile_main, compile_app, make_static_lib)

## 4. Detailed Shell Task Example

compile_lib1 resolves:
- file_inputs[0] -> ../workflows/lib1.cpp
- file_outputs[0] -> ../workflows/lib1.o
args: ["${input[0]}", "${output[0]}"] -> becomes the resolved paths.

## 5. Re-running the workflow

With freshness checks implemented for JCWF:
- If outputs exist and are newer than all inputs and upstream outputs, tasks are skipped as up-to-date.
- Touching lib1.cpp should rebuild lib1.o, then libmylib.a, then myapp.

---
```

### 7.5 `PROB_make_process_context.output.txt` (generated JCWF)

```json
{
  "version": "1.0",
  "id": "make-example",
  "label": "Makefile-Style Build Workflow",
  "doc": "Build example: compile sources, archive static lib, link executable using shell tasks.",
  "triggers": [
    {
      "type": "auto",
      "id": "auto",
      "enabled": true,
      "params": {}
    }
  ],
  "tasks": {
    "compile_lib1": {
      "id": "compile_lib1",
      "type": "shell",
      "label": "Compile lib1.cpp to lib1.o",
      "file_inputs": ["lib1.cpp"],
      "file_outputs": ["lib1.o"],
      "params": {
        "command": "scripts/compile.sh",
        "args": ["${input[0]}", "${output[0]}", "-O3"]
      },
      "outputs": {
        "object": { "type": "string" }
      }
    },
    "compile_lib2": {
      "id": "compile_lib2",
      "type": "shell",
      "label": "Compile lib2.cpp to lib2.o",
      "file_inputs": ["lib2.cpp"],
      "file_outputs": ["lib2.o"],
      "params": {
        "command": "scripts/compile.sh",
        "args": ["${input[0]}", "${output[0]}", "-O3"]
      },
      "outputs": {
        "object": { "type": "string" }
      }
    },
    "make_static_lib": {
      "id": "make_static_lib",
      "type": "shell",
      "label": "Archive lib1.o and lib2.o into libmylib.a",
      "depends_on": ["compile_lib1", "compile_lib2"],
      "file_inputs": ["lib1.o", "lib2.o"],
      "file_outputs": ["libmylib.a"],
      "params": {
        "command": "scripts/archive.sh",
        "args": ["${input[0]}", "${input[1]}", "${output[0]}"]
      },
      "inputs": {
        "obj1": { "type": "string", "required": true },
        "obj2": { "type": "string", "required": true }
      },
      "outputs": {
        "archive": { "type": "string" }
      }
    },
    "compile_main": {
      "id": "compile_main",
      "type": "shell",
      "label": "Compile main.cpp to main.o",
      "file_inputs": ["main.cpp"],
      "file_outputs": ["main.o"],
      "params": {
        "command": "scripts/compile.sh",
        "args": ["${input[0]}", "${output[0]}", "-O3"]
      },
      "outputs": {
        "object": { "type": "string" }
      }
    },
    "compile_app": {
      "id": "compile_app",
      "type": "shell",
      "label": "Compile app.cpp to app.o",
      "file_inputs": ["app.cpp"],
      "file_outputs": ["app.o"],
      "params": {
        "command": "scripts/compile.sh",
        "args": ["${input[0]}", "${output[0]}", "-O3"]
      },
      "outputs": {
        "object": { "type": "string" }
      }
    },
    "make_executable": {
      "id": "make_executable",
      "type": "shell",
      "label": "Link main.o, app.o, libmylib.a into myapp",
      "depends_on": ["compile_main", "compile_app", "make_static_lib"],
      "file_inputs": ["main.o", "app.o", "libmylib.a"],
      "file_outputs": ["myapp"],
      "params": {
        "command": "scripts/link.sh",
        "args": ["${input[0]}", "${input[1]}", "${input[2]}", "${output[0]}", "-O3"]
      },
      "inputs": {
        "main_obj": { "type": "string", "required": true },
        "app_obj": { "type": "string", "required": true },
        "archive": { "type": "string", "required": true }
      }
    }
  },
  "dataflow": [
    {
      "from_task": "compile_lib1",
      "from_output": "object",
      "to_task": "make_static_lib",
      "to_input": "obj1"
    },
    {
      "from_task": "compile_lib2",
      "from_output": "object",
      "to_task": "make_static_lib",
      "to_input": "obj2"
    },
    {
      "from_task": "make_static_lib",
      "from_output": "archive",
      "to_task": "make_executable",
      "to_input": "archive"
    },
    {
      "from_task": "compile_main",
      "from_output": "object",
      "to_task": "make_executable",
      "to_input": "main_obj"
    },
    {
      "from_task": "compile_app",
      "from_output": "object",
      "to_task": "make_executable",
      "to_input": "app_obj"
    }
  ]
}
```
